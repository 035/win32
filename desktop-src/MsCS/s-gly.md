---
title: S
description: A B C D E F G H I J K L M N O P Q R S T U V W X Y Z
Robots: noindex, nofollow
audience: developer
author: REDMOND\\markl
manager: REDMOND\\markl
ms.assetid: bde2f183-519b-4b49-b75d-2b3e3ba895d1
ms.prod: windows-server-dev
ms.technology: failover-clustering
ms.tgt_platform: multiple
ms.author: windowssdkdev
ms.topic: article
ms.date: 05/31/2018
---

# S

[A](a-gly.md) B [C](c-gly.md) [D](d-gly.md) [E](e-gly.md) [F](f-gly.md) [G](g-gly.md) [H](h-gly.md) [I](i-gly.md) J K [L](l-gly.md) [M](m-gly.md) [N](n-gly.md) [O](o-gly.md) [P](p-gly.md) [Q](q-gly.md) [R](r-gly.md) S [T](t-gly.md) U [V](v-gly.md) [W](w-gly.md) X Y Z

<dl> <dt>

<span id="_wolf_scsi_gly"></span><span id="_WOLF_SCSI_GLY"></span>**SCSI**
</dt> <dd>

See [*Small Computer System Interface*](#-wolf-small-computer-system-interface-gly).

</dd> <dt>

<span id="_wolf_scalability_gly"></span><span id="_WOLF_SCALABILITY_GLY"></span>**scalability**
</dt> <dd>

A measure of how well a computer system can grow to meet increasing demands.

</dd> <dt>

<span id="_wolf_server_application_gly"></span><span id="_WOLF_SERVER_APPLICATION_GLY"></span>**server application**
</dt> <dd>

The server side of the [*client-server model*](https://www.bing.com/search?q=*client-server model*). The server waits for requests from its clients. When it receives a request, the server processes it and returns the requested information to the client.

</dd> <dt>

<span id="_wolf_server_cluster_gly"></span><span id="_WOLF_SERVER_CLUSTER_GLY"></span>**server cluster**
</dt> <dd>

See [*failover cluster*](https://www.bing.com/search?q=*failover cluster*).

</dd> <dt>

<span id="_wolf_server_cluster_api_gly"></span><span id="_WOLF_SERVER_CLUSTER_API_GLY"></span>**Server Cluster API**
</dt> <dd>

See [*Failover Cluster API*](https://www.bing.com/search?q=*Failover Cluster API*).

</dd> <dt>

<span id="_wolf_server_cluster_object_gly"></span><span id="_WOLF_SERVER_CLUSTER_OBJECT_GLY"></span>**server cluster object**
</dt> <dd>

See [*cluster object*](https://www.bing.com/search?q=*cluster object*).

</dd> <dt>

<span id="_wolf_service_gly"></span><span id="_WOLF_SERVICE_GLY"></span>**service**
</dt> <dd>

Data or operation made available to network clients through a [*failover cluster instance*](https://www.bing.com/search?q=*failover cluster instance*); not necessarily a service.

</dd> <dt>

<span id="_wolf_shared_disk_gly"></span><span id="_WOLF_SHARED_DISK_GLY"></span>**shared disk**
</dt> <dd>

A disk shared between multiple owners simultaneously. [*Failover cluster*](https://www.bing.com/search?q=*Failover cluster*) do not use shared disks. A [*cluster disk*](https://www.bing.com/search?q=*cluster disk*) is owned by only one [*node*](https://www.bing.com/search?q=*node*) at any point in time.

</dd> <dt>

<span id="_wolf_shared_nothing_model_gly"></span><span id="_WOLF_SHARED_NOTHING_MODEL_GLY"></span>**shared nothing model**
</dt> <dd>

Clustering architecture where systems share neither memory nor devices. Each processor has its own memory and a copy of the operating system. Connections between processors are optimized because messages are passed across a high-speed, dedicated bus. Server clusters implements this model.

</dd> <dt>

<span id="_wolf_shared_resource_gly"></span><span id="_WOLF_SHARED_RESOURCE_GLY"></span>**shared resource**
</dt> <dd>

Cluster organization in which some [*resources*](https://www.bing.com/search?q=*resources*) are accessible to all systems in the [*cluster*](https://www.bing.com/search?q=*cluster*).

</dd> <dt>

<span id="_wolf_single_point_of_failure_gly"></span><span id="_WOLF_SINGLE_POINT_OF_FAILURE_GLY"></span>**single point of failure**
</dt> <dd>

A single hardware or software component that prevents a [*cluster*](https://www.bing.com/search?q=*cluster*) from functioning if the component fails. Administrators try to avoid single points of failure through redundancy and backup systems.

</dd> <dt>

<span id="_wolf_small_computer_system_interface_gly"></span><span id="_WOLF_SMALL_COMPUTER_SYSTEM_INTERFACE_GLY"></span>**Small Computer System Interface (SCSI)**
</dt> <dd>

A protocol for connecting devices from several classes of peripherals to a host system without requiring modifications to hardware and software.

</dd> <dt>

<span id="_wolf_storage_class_resource_gly"></span><span id="_WOLF_STORAGE_CLASS_RESOURCE_GLY"></span>**storage class resource**
</dt> <dd>

A data storage device that is accessible to all cluster [*nodes*](https://www.bing.com/search?q=*nodes*) and that is able to operate as a cluster [*resource*](https://www.bing.com/search?q=*resource*). An example of a storage class resource is the [Physical Disk](physical-disk.md) resource.

</dd> <dt>

<span id="_wolf_storage_pool_gly"></span><span id="_WOLF_STORAGE_POOL_GLY"></span>**storage pool**
</dt> <dd>

A collection of *storage class resources*. For a storage pool to be clusterable, the pool must contain at least 3 [physical disk](physical-disk.md) resources. In addition, each physical disk resource in the storage pool cannot (1) have a storage capacity of 10 GB or less, (2) use thin provisioning, or (3) have a mix of storage spaces or other file systems (for example, NTFS).

</dd> <dt>

<span id="_wolf_stripe_set_gly"></span><span id="_WOLF_STRIPE_SET_GLY"></span>**stripe set**
</dt> <dd>

See [*disk striping*](https://www.bing.com/search?q=*disk striping*).

</dd> <dt>

<span id="_wolf_system_gly"></span><span id="_WOLF_SYSTEM_GLY"></span>**system**
</dt> <dd>

See [*node*](https://www.bing.com/search?q=*node*).

</dd> </dl>

 

 




